<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Admin - Screen Audio Broadcast</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      text-align: center;
      padding: 20px;
      margin: 0;
      min-height: 100vh;
    }
    
    .container {
      max-width: 700px;
      margin: 0 auto;
      background: rgba(255, 255, 255, 0.1);
      padding: 40px;
      border-radius: 20px;
      backdrop-filter: blur(10px);
    }
    
    h1 {
      color: #ff6b35;
      margin-bottom: 30px;
      font-size: 2.5rem;
    }
    
    .mode-selection {
      background: rgba(0, 0, 0, 0.2);
      padding: 25px;
      border-radius: 15px;
      margin: 25px 0;
    }
    
    .mode-option {
      background: rgba(255, 255, 255, 0.1);
      padding: 20px;
      margin: 15px 0;
      border-radius: 12px;
      border: 2px solid transparent;
      cursor: pointer;
      transition: all 0.3s ease;
    }
    
    .mode-option:hover {
      border-color: #ff6b35;
      background: rgba(255, 107, 53, 0.2);
    }
    
    .mode-option.selected {
      border-color: #2ecc71;
      background: rgba(46, 204, 113, 0.2);
    }
    
    .mode-title {
      font-size: 1.3rem;
      font-weight: bold;
      margin-bottom: 8px;
      color: #ff6b35;
    }
    
    .mode-desc {
      font-size: 1rem;
      opacity: 0.9;
    }
    
    .status {
      padding: 20px;
      margin: 20px 0;
      background: rgba(0, 0, 0, 0.3);
      border-radius: 15px;
      font-size: 1.2rem;
    }
    
    .btn {
      background: linear-gradient(45deg, #ff6b35, #f7931e);
      color: white;
      border: none;
      padding: 18px 35px;
      font-size: 1.2rem;
      border-radius: 30px;
      cursor: pointer;
      margin: 15px;
      min-width: 200px;
      font-weight: 600;
    }
    
    .btn:disabled {
      background: #666;
      cursor: not-allowed;
    }
    
    .btn.stop {
      background: linear-gradient(45deg, #e74c3c, #c0392b);
    }
    
    .success {
      background: rgba(46, 204, 113, 0.3) !important;
      color: #2ecc71 !important;
    }
    
    .error {
      background: rgba(231, 76, 60, 0.3) !important;
      color: #e74c3c !important;
    }
    
    .streaming {
      background: rgba(52, 152, 219, 0.3) !important;
      color: #3498db !important;
    }
    
    .instructions {
      background: rgba(46, 204, 113, 0.2);
      color: #2ecc71;
      padding: 20px;
      border-radius: 12px;
      margin: 20px 0;
      text-align: left;
      font-size: 0.95rem;
    }
    
    .warning {
      background: rgba(243, 156, 18, 0.2);
      color: #f39c12;
      padding: 15px;
      border-radius: 10px;
      margin: 15px 0;
      font-size: 0.9rem;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è Admin - Screen Audio Broadcast</h1>
    
    <div class="mode-selection">
      <h3>Choose Audio Source:</h3>
      
      <div class="mode-option" onclick="selectMode('microphone')" id="micMode">
        <div class="mode-title">üé§ Microphone Only</div>
        <div class="mode-desc">Broadcast your voice through microphone</div>
      </div>
      
      <div class="mode-option selected" onclick="selectMode('screen')" id="screenMode">
        <div class="mode-title">üñ•Ô∏è Screen Audio</div>
        <div class="mode-desc">Broadcast audio from your screen (YouTube, Spotify, etc.)</div>
      </div>
      
      <div class="mode-option" onclick="selectMode('mixed')" id="mixedMode">
        <div class="mode-title">üéµ Mixed Audio</div>
        <div class="mode-desc">Broadcast screen audio + microphone together</div>
      </div>
    </div>
    
    <div class="instructions" id="instructions">
      <strong>üñ•Ô∏è Screen Audio Mode:</strong><br>
      ‚Ä¢ Click "Start Broadcasting" below<br>
      ‚Ä¢ Browser will ask to share your screen<br>
      ‚Ä¢ Choose "Share audio" or select a specific tab with audio<br>
      ‚Ä¢ Perfect for streaming music from Spotify, YouTube, etc.
    </div>
    
    <div class="warning">
      ‚ö†Ô∏è <strong>Note:</strong> Screen audio capture requires a modern browser (Chrome 94+, Firefox 92+, Edge 94+)
    </div>
    
    <div class="status" id="statusDisplay">
      üì° Ready to broadcast screen audio
      <div style="font-size: 0.9rem; margin-top: 5px;">
        Render Health: <span id="render-health" style="color: #f39c12;">Checking...</span>
      </div>
    </div>
    
    <div>
      <button class="btn" id="startBtn" onclick="startBroadcast()">
        üöÄ Start Broadcasting
      </button>
      <button class="btn stop" id="stopBtn" onclick="stopBroadcast()" style="display: none;">
        üõë Stop Broadcasting
      </button>
    </div>
  </div>

  <script>
    // Render-optimized audio streaming constants
    const SAMPLE_RATE = 48000;
    const CHANNELS = 2;
    const BUFFER_SIZE = 4096;
    
    let websocket = null;
    let audioContext = null;
    let isRecording = false;
    let processor = null;
    let source = null;
    let currentMode = 'screen';
    let renderHealth = 'checking';
    let sendCount = 0;
    let sendErrors = 0;
    
    const statusDisplay = document.getElementById('statusDisplay');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const instructions = document.getElementById('instructions');

    // Select broadcast mode
    function selectMode(mode) {
      currentMode = mode;
      
      // Update UI
      document.querySelectorAll('.mode-option').forEach(el => el.classList.remove('selected'));
      document.getElementById(mode + 'Mode').classList.add('selected');
      
      // Update instructions
      updateInstructions(mode);
    }

    // Update instructions based on mode
    function updateInstructions(mode) {
      const instructionTexts = {
        microphone: `
          <strong>üé§ Microphone Mode:</strong><br>
          ‚Ä¢ Click "Start Broadcasting" below<br>
          ‚Ä¢ Allow microphone access<br>
          ‚Ä¢ Speak into your microphone to broadcast
        `,
        screen: `
          <strong>üñ•Ô∏è Screen Audio Mode:</strong><br>
          ‚Ä¢ Click "Start Broadcasting" below<br>
          ‚Ä¢ Browser will ask to share your screen<br>
          ‚Ä¢ Choose "Share audio" or select a specific tab with audio<br>
          ‚Ä¢ Perfect for streaming music from Spotify, YouTube, etc.
        `,
        mixed: `
          <strong>üéµ Mixed Audio Mode:</strong><br>
          ‚Ä¢ Click "Start Broadcasting" below<br>
          ‚Ä¢ Allow both microphone and screen audio access<br>
          ‚Ä¢ Your voice + screen audio will be mixed together<br>
          ‚Ä¢ Great for DJ-style broadcasting with commentary
        `
      };
      
      instructions.innerHTML = instructionTexts[mode];
    }

    // Start Render-optimized broadcasting
    async function startBroadcast() {
      try {
        updateStatus('üîÑ Setting up Render-optimized audio capture...', 'streaming');
        
        let stream;
        
        if (currentMode === 'microphone') {
          // Render-optimized microphone capture
          stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
              sampleRate: SAMPLE_RATE,
              channelCount: 1
            }
          });
          
        } else if (currentMode === 'screen') {
          // Render-optimized screen audio capture
          updateStatus('üñ•Ô∏è Please select screen/tab to share audio...', 'streaming');
          
          stream = await navigator.mediaDevices.getDisplayMedia({
            video: false,
            audio: {
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
              sampleRate: SAMPLE_RATE,
              channelCount: CHANNELS
            }
          });
          
        } else if (currentMode === 'mixed') {
          // Render-optimized mixed audio
          updateStatus('üéµ Setting up mixed audio (mic + screen)...', 'streaming');
          
          const micStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
              sampleRate: SAMPLE_RATE
            }
          });
          
          const screenStream = await navigator.mediaDevices.getDisplayMedia({
            video: false,
            audio: {
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
              sampleRate: SAMPLE_RATE
            }
          });
          
          // Mix both streams using Web Audio API
          audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: SAMPLE_RATE
          });
          
          await audioContext.resume();
          
          const micSource = audioContext.createMediaStreamSource(micStream);
          const screenSource = audioContext.createMediaStreamSource(screenStream);
          const destination = audioContext.createMediaStreamDestination();
          
          // Mix both sources
          micSource.connect(destination);
          screenSource.connect(destination);
          
          stream = destination.stream;
        }
        
        updateStatus('üåê Connecting to Render server...', 'streaming');
        
        // Connect to Render WebSocket
        await connectRenderWebSocket();
        
        updateStatus('üéôÔ∏è Processing Render-optimized audio...', 'streaming');
        
        // Create Render-optimized audio context
        if (!audioContext) {
          audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: SAMPLE_RATE
          });
          await audioContext.resume();
        }
        
        // Create Render-optimized audio processing pipeline
        source = audioContext.createMediaStreamSource(stream);
        processor = audioContext.createScriptProcessor(BUFFER_SIZE, CHANNELS, CHANNELS);
        
        processor.onaudioprocess = function(event) {
          if (isRecording && websocket && websocket.readyState === WebSocket.OPEN) {
            const inputBuffer = event.inputBuffer;
            const outputData = new Int16Array(BUFFER_SIZE * CHANNELS);
            
            // Render-optimized stereo processing
            for (let channel = 0; channel < Math.min(inputBuffer.numberOfChannels, CHANNELS); channel++) {
              const channelData = inputBuffer.getChannelData(channel);
              for (let i = 0; i < BUFFER_SIZE; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                outputData[i * CHANNELS + channel] = Math.round(sample * 32767);
              }
            }
            
            // Fill missing channel if mono input
            if (inputBuffer.numberOfChannels === 1 && CHANNELS === 2) {
              for (let i = 0; i < BUFFER_SIZE; i++) {
                outputData[i * CHANNELS + 1] = outputData[i * CHANNELS];
              }
            }
            
            try {
              websocket.send(outputData.buffer);
              sendCount++;
              
              if (sendCount % 100 === 0) {
                console.log(`üì° Sent ${sendCount} chunks to Render (${sendErrors} errors)`);
                updateRenderStats();
              }
            } catch (error) {
              sendErrors++;
              console.error('Render send error:', error);
            }
          }
        };
        
        // Connect audio nodes
        source.connect(processor);
        processor.connect(audioContext.destination);
        
        // Start recording
        isRecording = true;
        
        // Update UI
        startBtn.style.display = 'none';
        stopBtn.style.display = 'inline-block';
        
        const modeNames = {
          microphone: 'microphone',
          screen: 'screen audio',
          mixed: 'mixed audio (mic + screen)'
        };
        
        updateStatus(`üéµ Broadcasting ${modeNames[currentMode]} to Render!`, 'success');
        
        console.log(`‚úÖ Render ${currentMode} broadcasting started`);
        
      } catch (error) {
        console.error('‚ùå Failed to start Render broadcast:', error);
        
        if (error.name === 'NotAllowedError') {
          updateStatus('‚ùå Permission denied. Please allow access to microphone/screen.', 'error');
        } else if (error.name === 'NotSupportedError') {
          updateStatus('‚ùå Screen audio capture not supported in this browser.', 'error');
        } else {
          updateStatus('‚ùå Failed to start: ' + error.message, 'error');
        }
      }
    }

    // Connect to Render-optimized WebSocket
    function connectRenderWebSocket() {
      return new Promise((resolve, reject) => {
        try {
          const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
          const wsUrl = protocol + '//' + window.location.host;
          
          websocket = new WebSocket(wsUrl);
          websocket.binaryType = 'arraybuffer';
          
          websocket.onopen = () => {
            console.log('‚úÖ Render WebSocket connected');
            resolve();
          };
          
          websocket.onclose = () => {
            console.log('‚ùå Render WebSocket disconnected');
            updateStatus('‚ùå Render connection lost', 'error');
            stopBroadcast();
          };
          
          websocket.onerror = (error) => {
            console.error('‚ùå Render WebSocket error:', error);
            updateStatus('‚ùå Render connection failed', 'error');
            reject(new Error('Render WebSocket connection failed'));
          };
          
        } catch (error) {
          reject(error);
        }
      });
    }

    // Stop Render broadcasting
    function stopBroadcast() {
      isRecording = false;
      
      // Disconnect audio processing
      if (processor) {
        processor.disconnect();
        processor = null;
      }
      
      if (source) {
        source.disconnect();
        source = null;
      }
      
      // Close audio context
      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }
      
      // Close Render WebSocket
      if (websocket) {
        websocket.close();
        websocket = null;
      }
      
      // Reset counters
      sendCount = 0;
      sendErrors = 0;
      
      // Update UI
      startBtn.style.display = 'inline-block';
      stopBtn.style.display = 'none';
      
      updateStatus('üì° Render broadcasting stopped');
      
      console.log('‚èπÔ∏è Render broadcasting stopped');
    }

    // Update Render statistics
    function updateRenderStats() {
      const errorRate = sendCount > 0 ? Math.round((sendErrors / sendCount) * 100) : 0;
      const quality = errorRate < 1 ? 'üü¢' : errorRate < 5 ? 'üü°' : 'üî¥';
      console.log(`Render stats: ${quality} ${sendCount} chunks, ${errorRate}% errors`);
    }

    // Check Render health
    async function checkRenderHealth() {
      try {
        const response = await fetch('/health');
        const data = await response.json();
        const healthSpan = document.getElementById('render-health');
        
        renderHealth = 'up';
        healthSpan.textContent = `‚úÖ UP (${data.clients} clients, ${Math.round(data.uptime)}s)`;
        healthSpan.style.color = '#2ecc71';
        
      } catch (error) {
        renderHealth = 'down';
        const healthSpan = document.getElementById('render-health');
        healthSpan.textContent = '‚ùå DOWN';
        healthSpan.style.color = '#e74c3c';
      }
    }

    // Update status display
    function updateStatus(message, type = '') {
      statusDisplay.textContent = message;
      statusDisplay.className = 'status';
      if (type) {
        statusDisplay.classList.add(type);
      }
    }

    // Cleanup on page unload
    window.addEventListener('beforeunload', () => {
      stopBroadcast();
    });

    // Initialize Render-optimized screen admin
    window.addEventListener('load', () => {
      console.log('üñ•Ô∏è Render Screen Audio Admin Panel loaded');
      updateInstructions('screen');
      
      // Check Render health immediately and every 30 seconds
      checkRenderHealth();
      setInterval(checkRenderHealth, 30000);
    });
  </script>
</body>
</html>
